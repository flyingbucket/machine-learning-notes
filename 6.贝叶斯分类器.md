## 贝叶斯公式

$$
\begin{aligned}
P(B_i|A)&=\frac{P(B_i)P(A|B_i)}{P(A)}\\
		&=\frac{P(B_i)P(A|B_i)}{\sum_{j=1}^nP(B_j)P(A|B_j)}\\
\end{aligned}
$$
在机器学习中一般写作：
$$
P(\theta|X)=\frac{P(X|\theta)P(\theta)}{P(X)}
$$
称$P(\theta)$为先验，$P(\theta|X)$为后验

## 基本概念
在二分类问题中，我们考虑一下几个概念：
- 两个类别$\omega_1,\omega_2$
- 先验概率$P(\omega_1),P(\omega_2)$ 
- 类条件概率密度$p(X|\omega_1),p(X|\omega_2)$
- 随机事件观察值，特征向量X
后验概率
- $P(\omega_1|X)=\frac{p(X|\omega_1)P(\omega)}{p(X)}$
- $P(\omega_2|X)=\frac{p(X|\omega_2)P(\omega)}{p(X)}$
- $P(X)=p(X|\omega_1)P(\omega_1)+p(X|\omega_2)P(\omega_2)$

*目标是找到最小错误概率的分类器*

## 决策规则
计算观测值的后验概率，将样本分入后验概率大的一类。