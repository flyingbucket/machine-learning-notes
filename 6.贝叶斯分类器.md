## 贝叶斯公式

$$
\begin{aligned}
P(B_i|A)&=\frac{P(B_i)P(A|B_i)}{P(A)}\\
		&=\frac{P(B_i)P(A|B_i)}{\sum_{j=1}^nP(B_j)P(A|B_j)}\\
\end{aligned}
$$
在机器学习中一般写作：
$$
P(\theta|X)=\frac{P(X|\theta)P(\theta)}{P(X)}
$$
称$P(\theta)$为先验，$P(\theta|X)$为后验

## 基本概念
在二分类问题中，我们考虑一下几个概念：
- 两个类别$\omega_1,\omega_2$
- 先验概率$P(\omega_1),P(\omega_2)$ 
- 类条件概率密度$p(X|\omega_1),p(X|\omega_2)$
- 随机事件观察值，特征向量X
后验概率
- $P(\omega_1|X)=\frac{p(X|\omega_1)P(\omega)}{p(X)}$
- $P(\omega_2|X)=\frac{p(X|\omega_2)P(\omega)}{p(X)}$
- $P(X)=p(X|\omega_1)P(\omega_1)+p(X|\omega_2)P(\omega_2)$

*目标是找到最小错误概率的分类器*

## 决策规则
以下几类决策规则相互等价：
- 后验概率：$P(\omega_1|X)>P(\omega_2|X)$则分入第一类，否则第二类
- 后验概率分子：$P(X|\omega_1)P(\omega_1)>P(X|\omega_2)P(\omega_2$则分入第一类，否则第二类
- 