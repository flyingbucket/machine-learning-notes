贝叶斯神经网络(BNN)是一种将网络参数“贝叶斯化”的神经网络。值得注意的是，BNN虽然也是有向无环图的结构，但它和BN是完全不同目的、不同结构的模型，不应混淆。

## 传统神经网络 vs 贝叶斯神经网络
传统的神经网络接受一系列特征数据作为输入，每一层的节点表示线性组合的计算结果和偏置项，边表示线性组合的权重，最终输出一个结果预测值，该结果用于构造损失函数，利用损失函数的梯度反向传播来学习出最优的网络参数（边上的权重和偏置项）。

如此学习所得到的神经网络，是该网络结构下各参数的点估计。

贝叶斯神经网络同样要求解网络参数，但它给出的**不是各参数的点估计，而是参数在给定数据下的后验分布**。

NN只是拿到一组固定的权重w,然后给一个x推理一个y;
而BNN是拿到w的分布，给出一个x后，在w的分布上抽样出很多组权重w,每组权重推理出一个y,最终输出的y是所有推理出的y按照w的分布的加权平均。
**这是BNN与传统NN的最根本区别**

**贝叶斯神经网络的输出为：**
$$
P(y|x)=E_{P(w|D)}P(y|x,w)=\int P(y|x,w)P(w|D)dw
$$

贝叶斯神经网络往往可以反映*预测结果*和*训练过程*的**不确定性**


## 贝叶斯神经网络的求解

### 变分推断

在贝叶斯神经网络（BNN）中，网络参数 $w$ 被视为随机变量。  
给定训练数据集 $D=\{(x_i,y_i)\}_{i=1}^N$，理论上的目标是求解参数的后验分布：

$$
P(w \mid D) = \frac{P(D \mid w)P(w)}{P(D)}
$$

其中：

- $P(w)$ 是参数的先验分布  
- $P(D\mid w)$ 是由神经网络定义的似然函数  
- $P(D)$ 是证据项（marginal likelihood）

由于神经网络的非线性结构，$P(w\mid D)$ 通常是 **不可解析、不可直接计算** 的。

####  变分推断的基本思想

变分推断通过引入一个**可计算的近似分布族** $q(w\mid\theta)$，来逼近真实后验分布：

$$
P(w\mid D) \approx q(w\mid\theta)
$$

其中：

- $q(w\mid\theta)$ 称为 **变分分布**
- $\theta$ 是变分分布的参数（不是网络权重）

目标是找到最优的 $\theta$，使得 $q(w\mid\theta)$ 尽可能接近 $P(w\mid D)$。

#### KL 散度作为优化目标

衡量两个分布之间差异的标准工具是 **KL 散度**：

$$
\theta^{*} = \arg\min_\theta D_{KL}\big(q(w\mid\theta)\,\|\,P(w\mid D)\big)
$$

KL 散度定义为：

$$
D_{KL}(q\|p) = \int q(w)\log\frac{q(w)}{p(w)}dw
$$
#### 推导变分目标函数

将 KL 散度展开，并代入贝叶斯公式：

$$
\begin{aligned}
D_{KL}\big(q(w\mid\theta)\,\|\,P(w\mid D)\big)
&= \int q(w\mid\theta)\log\frac{q(w\mid\theta)}{P(w\mid D)}dw \\
&= \int q(w\mid\theta)\log\frac{q(w\mid\theta)P(D)}{P(w)P(D\mid w)}dw
\end{aligned}
$$

将对数项拆分：

$$
\log\frac{q(w\mid\theta)P(D)}{P(w)P(D\mid w)}
=
\log\frac{q(w\mid\theta)}{P(w)}
-
\log P(D\mid w)
+
\log P(D)
$$

代回并整理：

$$
\begin{aligned}
D_{KL}
&= \int q(w\mid\theta)\log\frac{q(w\mid\theta)}{P(w)}dw
- \int q(w\mid\theta)\log P(D\mid w)dw
+ \log P(D)
\end{aligned}
$$

其中：
- $\log P(D)$ 与 $\theta$ 无关，可视为常数

#### ELBO 与最终优化目标

忽略常数项 $\log P(D)$，等价地最小化以下目标函数：

$$
F(D,\theta)
=
-\mathbb E_{q(w\mid\theta)}[\log P(D\mid w)]
+
D_{KL}\big(q(w\mid\theta)\,\|\,P(w)\big)
$$

该目标函数也可理解为 **负的 ELBO（Evidence Lower Bound）**。

---

#### 各项的直观解释

##### 期望负对数似然项

$$
-\mathbb E_{q(w\mid\theta)}[\log P(D\mid w)]
$$

- 对应数据拟合项  
- 类似于传统神经网络中的损失函数  
- 区别在于：BNN 中需要对参数分布取期望

##### KL 正则项

$$
D_{KL}\big(q(w\mid\theta)\,\|\,P(w)\big)
$$

- 约束后验分布不要偏离先验分布太远  
- 起到正则化作用  
- 在效果上类似于 $L_2$ 正则，但具有明确的贝叶斯含义


### 正态变分分布与重参数化技巧

*从这里开始都是gpt写的*

在完成 ELBO（Evidence Lower Bound）的推导后，贝叶斯神经网络（BNN）的训练问题被转化为一个可优化的目标函数：

$$
\mathcal L(\theta)
=
-\mathbb E_{q(w\mid\theta)}[\log p(D\mid w)]
+
D_{KL}\big(q(w\mid\theta)\,\|\,p(w)\big)
$$

其中，核心困难在于第一项关于 $q(w\mid\theta)$ 的期望通常不可解析。为此，需要对变分分布作进一步假设，并引入重参数化技巧。


### 正态变分分布假设（Gaussian Variational Posterior）

一种最常见、也是工程中最可行的假设是 **mean-field Gaussian**：

$$
q(w\mid\theta) = \mathcal N\big(w;\ \mu,\ \mathrm{diag}(\sigma^2)\big)
$$

其中：
- $w$ 表示神经网络的所有权重与偏置
- $\mu$ 为均值向量
- $\sigma^2$ 为方差向量（假设各维独立）
- 变分参数为 $\theta = (\mu, \sigma)$

为保证数值稳定性，实际实现中常使用 $\rho$ 进行参数化：

$$
\sigma = \mathrm{softplus}(\rho)
$$

### KL 散度项的闭式解

若先验分布取为各向同性高斯：

$$
p(w) = \mathcal N(0,\ \sigma_0^2 I)
$$

则 KL 散度项可以解析计算：

$$
D_{KL}(q(w)\|p(w))
=
\frac{1}{2}\sum_j
\left(
\frac{\sigma_j^2 + \mu_j^2}{\sigma_0^2}
- 1
+ \log\frac{\sigma_0^2}{\sigma_j^2}
\right)
$$

该项在训练过程中无需采样，梯度稳定，起到类似正则化的作用。

### 重参数化技巧（Reparameterization Trick）

期望项 $\mathbb E_{q(w\mid\theta)}[\log p(D\mid w)]$ 仍然不可直接计算。  
重参数化技巧的核心思想是：**将随机性从参数中剥离出来**。

具体做法是引入辅助随机变量：

$$
\varepsilon \sim \mathcal N(0, I)
$$

并将 $w$ 表示为：

$$
w = \mu + \sigma \odot \varepsilon
$$

此时：
- 随机性完全来自 $\varepsilon$
- $\mu$ 和 $\sigma$ 成为可导的确定性变量
- 可以通过反向传播对 $\theta$ 求梯度


### Monte Carlo 近似期望项

利用重参数化后，可以用 Monte Carlo 方法近似期望：

$$
\mathbb E_{q(w)}[\log p(D\mid w)]
\approx
\frac{1}{S}\sum_{s=1}^S \log p(D\mid w^{(s)})
$$

其中：

$$
w^{(s)} = \mu + \sigma \odot \varepsilon^{(s)},\quad
\varepsilon^{(s)} \sim \mathcal N(0,I)
$$

在实际训练中，通常取 $S=1$ 即可获得稳定收敛。

### mini-batch 下的 ELBO 估计

对于一个大小为 $|B|$ 的 mini-batch $B$，全数据集大小为 $N$，期望对数似然项近似为：

$$
\log p(D\mid w)
\approx
\frac{N}{|B|}
\sum_{(x_i,y_i)\in B}
\log p(y_i\mid x_i,w)
$$

因此，mini-batch 下的训练目标可写为：

$$
\mathcal L_B(\theta)
=
-\frac{N}{|B|}
\sum_{(x_i,y_i)\in B}
\log p(y_i\mid x_i,w)
+
D_{KL}(q(w)\|p(w))
$$

---

### 训练过程总结

BNN 在采用正态变分分布与重参数化后，其训练流程可概括为：

1. 从 $\varepsilon \sim \mathcal N(0,I)$ 采样
2. 构造 $w = \mu + \sigma \odot \varepsilon$
3. 使用 $w$ 执行一次前向传播
4. 计算负对数似然损失
5. 加上 KL 散度正则项
6. 对 $\mu$ 和 $\rho$ 反向传播并更新

---

### 推理阶段的预测方式

在测试阶段，预测分布通过对参数后验进行 Monte Carlo 积分近似：

$$
p(y\mid x,D)
\approx
\frac{1}{S}
\sum_{s=1}^S
p(y\mid x,w^{(s)}),
\quad
w^{(s)} \sim q(w\mid\theta^\*)
$$

该过程不仅给出预测均值，还可用于估计模型的不确定性。

---

### 小结

- 正态变分分布使 BNN 的后验建模变得可计算
- 重参数化技巧使随机采样与梯度优化兼容
- BNN 的训练在形式上类似“带 KL 正则的随机权重神经网络”
- 推理阶段通过多次采样自然获得预测不确定性
