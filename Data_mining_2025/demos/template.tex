\documentclass[a4paper,12pt]{report}
\usepackage[margin=1in]{geometry} % to change the page dimensions
\usepackage{ctex}
\usepackage{xeCJK}
\usepackage{comment}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
%\usepackage{times}
\usepackage{setspace}
% \usepackage{lastpage}
\usepackage{fancyhdr}
\usepackage{graphicx}
%\graphicspath{{fig/}}
\usepackage{wrapfig}
\usepackage{subfigure}
\usepackage{array}  
% \usepackage{fontspec,xunicode,xltxtra}
% \renewcommand{\sfdefault}{cmr}
\usepackage{titlesec}
\usepackage{titletoc}
\usepackage[titletoc]{appendix}
%\usepackage[top=30mm,bottom=30mm,left=20mm,right=20mm]{geometry}
%\usepackage{cite}
\usepackage[backend = biber, style = gb7714-2015, defernumbers=true]{biblatex}
\renewcommand*{\bibfont}{\small}
\addbibresource{reference.bib}
%\usepackage{courier}
\setmonofont{Courier New}
\usepackage{listings}
\lstset{tabsize=4, keepspaces=true,
    xleftmargin=2em,xrightmargin=0em, aboveskip=1em,
    %backgroundcolor=\color{gray!20},  % 定义背景颜色
    frame=none,                       % 表示不要边框
    extendedchars=false,              % 解决代码跨页时，章节标题，页眉等汉字不显示的问题
    numberstyle=\ttfamily,
    basicstyle=\ttfamily,
    keywordstyle=\color{blue}\bfseries,
    breakindent=10pt,
    identifierstyle=,                 % nothing happens
    commentstyle=\color{green}\small,  % 注释的设置
    morecomment=[l][\color{green}]{\#},
    numbers=left,stepnumber=1,numberstyle=\scriptsize,
    showstringspaces=false,
    showspaces=false,
    flexiblecolumns=true,
    breaklines=true, breakautoindent=true,breakindent=4em,
    escapeinside={/*@}{@*/},
}
\usepackage{amsmath}
\usepackage{amsthm}
\newtheorem{theorem}{定理}
\newtheorem{definition}{定义}
\newtheorem{corollary}{推论}
\newtheorem{example}{例}
\usepackage{amsfonts}
%\usepackage{bm}
\usepackage{booktabs} % for much better looking tables
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfigure} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...
\usepackage{cases} %equation set
\usepackage{multirow} %use table
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{hyperref}
\hypersetup{colorlinks,linkcolor=black,anchorcolor=black,citecolor=black, pdfstartview=FitH,bookmarksnumbered=true,bookmarksopen=true,} % set href in tex & pdf
%\usepackage[framed,numbered,autolinebreaks,useliterate]{mcode} % 插入matlab代码
\XeTeXlinebreaklocale "zh"
\XeTeXlinebreakskip = 0pt plus 1pt minus 0.1pt

\makeatletter
\newenvironment{breakablealgorithm}
  {% \begin{breakablealgorithm}
   \begin{center}
     \refstepcounter{algorithm}% New algorithm
     \hrule height.8pt depth0pt \kern2pt% \@fs@pre for \@fs@ruled
     \renewcommand{\caption}[2][\relax]{% Make a new \caption
       {\raggedright\textbf{\ALG@name~\thealgorithm} ##2\par}%
       \ifx\relax##1\relax % #1 is \relax
         \addcontentsline{loa}{algorithm}{\protect\numberline{\thealgorithm}##2}%
       \else % #1 is not \relax
         \addcontentsline{loa}{algorithm}{\protect\numberline{\thealgorithm}##1}%
       \fi
       \kern2pt\hrule\kern2pt
     }
  }{% \end{breakablealgorithm}
     \kern2pt\hrule\relax% \@fs@post for \@fs@ruled
   \end{center}
  }
\makeatother
%%%%此处break 算法
%---------------------------------------------------------------------
%	页眉页脚设置
%---------------------------------------------------------------------
\fancypagestyle{plain}{
    \pagestyle{fancy}      %改变章节首页页眉
}

\pagestyle{fancy}
\lhead{\kaishu~数据挖掘实验报告~}
%\rhead{\kaishu~xxx}
\cfoot{\thepage}
\titleformat{\chapter}{\centering\zihao{2}\heiti}{第\chinese{chapter}章}{1em}{}
% \titleformat{\chapter*}{\centering\zihao{-1}\heiti}
\begin{comment}
%---------------------------------------------------------------------
%	章节标题设置
%---------------------------------------------------------------------
\titleformat{\chapter}{\centering\zihao{-1}\heiti}{实验\chinese{chapter}}{1em}{}
\titlespacing{\chapter}{0pt}{*0}{*6}
\end{comment}
%---------------------------------------------------------------------
%	摘要标题设置
%---------------------------------------------------------------------
%\renewcommand{\abstractname}{摘要}
\renewcommand{\figurename}{图}
\renewcommand{\tablename}{表}

%---------------------------------------------------------------------
%	参考文献设置
%---------------------------------------------------------------------
%\renewcommand{\bibname}{\zihao{2}{\hspace{\fill}参\hspace{0.5em}考\hspace{0.5em}文\hspace{0.5em}献\hspace{\fill}}}
\renewcommand{\bibname}{参考文献}
\begin{comment}
%---------------------------------------------------------------------
%	引用文献设置为上标
%---------------------------------------------------------------------
\makeatletter
\def\@cite#1#2{\textsuperscript{[{#1\if@tempswa , #2\fi}]}}
\makeatother
\end{comment}
%---------------------------------------------------------------------
%	目录页设置
%---------------------------------------------------------------------
%\renewcommand{\contentsname}{\zihao{-3} 目\quad 录}
\renewcommand{\contentsname}{目录}
\titlecontents{chapter}[0em]{\songti\zihao{-4}}{\thecontentslabel\ }{}
{\hspace{.5em}\titlerule*[4pt]{$\cdot$}\contentspage}
\titlecontents{section}[2em]{\vspace{0.1\baselineskip}\songti\zihao{-4}}{\thecontentslabel\ }{}
{\hspace{.5em}\titlerule*[4pt]{$\cdot$}\contentspage}
\titlecontents{subsection}[4em]{\vspace{0.1\baselineskip}\songti\zihao{-4}}{\thecontentslabel\ }{}
{\hspace{.5em}\titlerule*[4pt]{$\cdot$}\contentspage}

\begin{document}
%---------------------------------------------------------------------
%	封面设置
%---------------------------------------------------------------------
\begin{titlepage}
    \begin{center}
        
    \includegraphics[width=0.60\textwidth]{nk_logo.pdf}\\
    \vspace{10mm}
    \hspace*{\fill} \\
    \textbf{\zihao{1}{数据挖掘实验报告}}\\
    \vspace{\fill}
    
\setlength{\extrarowheight}{3mm}
{\songti\zihao{3}	
\begin{tabular}{rl}
    
    {\makebox[4\ccwd][s]{学\qquad 号：}} & ~\kaishu   \\
    {\makebox[4\ccwd][s]{姓\qquad 名：}} & ~\kaishu   \\
    {\makebox[4\ccwd][s]{年\qquad 级：}} & ~\kaishu   \\
    {\makebox[4\ccwd][s]{学\qquad 院：}} & ~\kaishu   \\
    {\makebox[4\ccwd][s]{专\qquad 业：}} & ~\kaishu   \\
    %{\makebox[4\ccwd][s]{授课教师：}}  & ~\kaishu xxx~教授\\ 
    %{\makebox[4\ccwd][s]{课程助教：}} & ~\kaishu xxx~xxx \\
    {\makebox[4\ccwd][s]{完成日期：}}  & ~\kaishu 2021年3月27日\\ 

\end{tabular}
 }\\[2cm]
%\vspace{\fill}
%\zihao{4}
%使用\LaTeX 撰写于\today
    \end{center}	
\end{titlepage}

%---------------------------------------------------------------------
%  摘要页
%---------------------------------------------------------------------


%---------------------------------------------------------------------
%  目录页
%---------------------------------------------------------------------
\tableofcontents % 生成目录

%---------------------------------------------------------------------
%  绪论
%---------------------------------------------------------------------
\chapter{第一次上机实验（LBP提取图像的纹理特征）}
\section{实验要求}
\begin{itemize}
\item{1. 给定若干张图像，利用局部二值模式特征(LBP)对这些图像进行特征提取}
\item{2. 图象是W * H * 3的矩阵}
\item{3. 将最终提取到的特征通过plot的形式展示，绘制特征曲线图直观对比不同类图片纹理提取到的特征的不同}
\item{4. 使用Python编程实现}
\end{itemize}
% \section{数据分析与处理}
% \par 没有可以不写，比如垂直平分分类器中
\section{实验步骤与原理}
\subsection{LBP 特征的基本定义}
局部二值模式（Local Binary Pattern, LBP）通过比较像素与其邻域像素的灰度关系，
编码局部纹理的微结构。给定中心像素 $g_c$ 及以其为中心、
半径为 $R$ 的圆形邻域上 $P$ 个等角度采样点的灰度 
$\{g_p\}_{p=0}^{P-1}$，标准 LBP 的定义为
\[
\mathrm{LBP}_{P,R}(x_c,y_c)
=\sum_{p=0}^{P-1} s(g_p-g_c)\,2^{p},\qquad
s(t)=\begin{cases}
1,& t\ge 0,\\
0,& t<0,
\end{cases}
\]
其中邻域采样点坐标为
\[
(x_p, y_p) = \bigl(x_c + R\cos(2\pi p/P),\; y_c - R\sin(2\pi p/P)\bigr),
\]
本次实验只考虑以$g_c$为中心的九宫格的局部的LBP特征。

\subsection{直方图特征}
将整幅图像（或图像块）内的 LBP 代码统计为直方图作为纹理特征：
\[
H[k]=\sum_{(x,y)} \mathbf{1}\{\mathrm{LBP}_{P,R}(x,y)=k\},\qquad k\in\{0,\dots,2^P-1\}.
\]
常见做法是对直方图进行 $\ell_1$ 归一化以消除尺寸影响：
\[
\hat H[k]=\frac{H[k]}{\sum_{j} H[j]}.
\]
为表征空间布局，可将图像划分为 $M\times N$ 个网格单元，分别计算直方图并按行优先串接，得到最终特征向量。


\subsection{实现细节（本实验手写 Python 要点）}
\begin{enumerate}
  \item \textbf{预处理：} 彩色图像先转灰度；可选高斯平滑抑制噪声。
  \item{按上述规则计算出图片的LBP特征直方图}
  \item \textbf{可视化：} 使用 Matplotlib 绘制折线；多类对比时可叠加均值曲线与标准差带。
\end{enumerate}

\subsection{复杂度与并行优化}
\begin{itemize}
  \item{时间复杂度约为 $O(PWH)$，$W,H$ 为图像宽高；$P$ 通常较小，易于并行/向量化。}
  \item{下面所呈现的代码采用串行方式计算LBP特征，但本人也给出了基于cython的并行加速版本。}
\end{itemize}

\noindent\textbf{加速计算技巧：}
\begin{itemize}
  \item{使用cython 的memoryview接口直接操作numpy.ndarray}
  \item{在cython层开启python的nogil模式，绕开全局解释器锁，使用OpenMP实现并行计算}
\end{itemize}

并行计算代码及各类计算方法的benchmark详见

\url{https://github.com/flyingbucket/machinelearning/tree/main/LBP}。
\section{实验结果与分析}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{../images/cloud_lbp_curves.png}
    \caption{cloud LBP 特征曲线对比图}
    \label{fig:cloud_lbp_curve}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{../images/forest_lbp_curves.png}
    \caption{forestLBP 特征曲线对比图}
    \label{forest_lbp_curve}
\end{figure}

\section{实验代码}
\begin{lstlisting}[language=Python]
  import numpy as np
  from matplotlib import pyplot as plt
  from collections import Counter
  from PIL import Image

  class LBP:
      @staticmethod
      def _read_img(imPath: str, pad: int = 1, mode: str = "reflect") -> np.ndarray:
          im = Image.open(imPath).convert("L")
          arr = np.array(im)
          padded = np.pad(arr, pad_width=((pad, pad), (pad, pad)), mode=mode)
          return padded

      @staticmethod
      def LBPkernel(im: np.ndarray, x, y) -> int:
          h, w = im.shape
          assert x + 2 < h and y + 2 < w, (
              f"Index out of bound,please check padding. x:{x},y:{y},h:{h},w:{w}"
          )
          patch = im[x : x + 3, y : y + 3].copy()
          patch = (patch >= patch[1, 1]).astype(np.uint8)
          idxs = [0, 1, 2, 5, 8, 7, 6, 3]
          bits = patch.reshape(-1)[idxs]
          val = int("".join(map(str, bits)), 2)
          return val

  def walk_dir(root_dir: str, out_dir: str = "EX1/outputs"):
      root = Path(root_dir)
      out = Path(out_dir)
      out.mkdir(parents=True, exist_ok=True)
      LBPcyExecutor = LBP()

      for class_dir in sorted([p for p in root.iterdir() if p.is_dir()]):
          hist_list = []
          img_names = []
          all_codes = set()
          for img_path in sorted(class_dir.iterdir()):
              try:
                  res_dict = LBPcyExecutor(str(img_path))  # {code: count}
                  if not isinstance(res_dict, dict) or len(res_dict) == 0:
                      print(f"[WARN] 空直方图：{img_path}")
                      continue
                  hist_list.append(res_dict)
                  img_names.append(img_path.stem)
                  all_codes.update(res_dict.keys())
              except Exception as e:
                  print(f"[WARN] 处理失败: {img_path} -> {e}")

          codes = sorted(all_codes)  # 所有出现过的 LBP code
          X = []  # 每张图对齐后的频率向量

          for h in hist_list:
              vec = np.array([h.get(c, 0) for c in codes], dtype=np.float64)
              X.append(vec)

          plt.figure(figsize=(10, 6))
          for vec, name in zip(X, img_names):
              plt.plot(codes, vec, linewidth=1.2, alpha=0.85, label=name)
          plt.xlabel("LBP code")
          plt.ylabel("count")
          plt.title(f"LBP feature curves - {class_dir.name}")
          plt.legend(ncol=2, fontsize=9, loc="best")
          plt.tight_layout()

          save_path = out / f"{class_dir.name}_lbp_curves.png"
          plt.savefig(save_path, dpi=160)
          plt.close()
          print(f"[OK] Saved: {save_path}")

  if __name__ == "__main__":
      dir = "./EX1/data"
      walk_dir(dir)

\end{lstlisting}
\clearpage
\chapter{第二次上机实验}
\section{实验要求}
\begin{itemize}
  \item 1. 根据分类结果（result.csv）绘制PR曲线
  \item 2. 使用Python编程实现
\end{itemize}
\section{数据分析与处理}

\textbf{数据分析}

数据给出了分类器在测试集上的推理结果，包含两列，lable和pred

\textbf{数据处理}

将数据按照预测值递减排序
\section{实验步骤与原理}

\subsection{原理说明}

在二分类任务中，分类器的输出通常为一个介于 $[0,1]$ 之间的预测概率或置信度分数。通过设定不同的阈值（Threshold），可以将样本划分为正类或负类，从而得到不同的分类结果。

针对每一个阈值 $\theta$，可计算以下指标：
\begin{itemize}
  \item \textbf{真正例（TP）}：预测为正类且实际为正类的样本数；
  \item \textbf{假正例（FP）}：预测为正类但实际为负类的样本数；
  \item \textbf{假负例（FN）}：预测为负类但实际为正类的样本数；
  \item \textbf{真负例（TN）}：预测为负类且实际为负类的样本数。
\end{itemize}

由此可计算两个关键性能指标：
\[
\text{Precision} = \frac{TP}{TP + FP}, \qquad
\text{Recall} = \frac{TP}{TP + FN}
\]

当阈值从 1 逐渐减小到 0 时，Recall 通常单调递增，而 Precision 可能上升或下降。将各个阈值对应的 $(\text{Recall}, \text{Precision})$ 点连接起来，即得到 \textbf{Precision–Recall (PR) 曲线}。

PR 曲线反映了模型在不同阈值下的精确率与召回率的权衡关系，常用于评估类别分布不平衡的分类任务。曲线下的面积（AUC-PR）越大，说明模型整体性能越优。

\subsection{实验步骤}

\begin{enumerate}
  \item \textbf{数据读取与排序}：使用 \texttt{pandas} 读取 \texttt{result.csv} 文件，并按照预测值 \texttt{pred} 从大到小排序；
  \item \textbf{计算累计统计量}：
    \begin{itemize}
      \item 通过布尔判断 \texttt{(label == 1)} 计算真正例的累计和（\texttt{tp\_cumsum}）；
      \item 通过 \texttt{(label == 0)} 计算假正例的累计和（\texttt{fp\_cumsum}）；
    \end{itemize}
  \item \textbf{计算 Precision 与 Recall}：
    \[
    \text{Precision}_i = \frac{\text{TP}_i}{\text{TP}_i + \text{FP}_i}, \qquad
    \text{Recall}_i = \frac{\text{TP}_i}{\text{TotalPos}}
    \]
    其中 \texttt{TotalPos} 为真实正样本总数。
  \item \textbf{绘制 PR 曲线}：
    使用 \texttt{matplotlib} 将 Recall 作为横轴，Precision 作为纵轴，绘制曲线图；
  \item \textbf{性能评估（可选）}：
    计算 PR 曲线下的面积（AUC–PR），作为模型整体性能指标。
\end{enumerate}

\subsection{实验意义}

通过本实验，掌握了从分类结果计算 Precision–Recall 曲线的完整流程，理解了模型阈值调整对分类性能的影响，并熟悉了使用 Python 对实验结果进行可视化的基本方法。

\section{实验结论与分析}
根据给出的示例数据绘制出的PR曲线如图\ref{fig:PRcurve}所示：
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{../images/PR_curve.png}
    \caption{示例数据的PR曲线}
    \label{fig:PRcurve}
\end{figure}
\section{实验代码}
\begin{lstlisting}[language=Python]
  import pandas as pd
  import numpy as np
  from matplotlib import pyplot as plt

  data = pd.read_csv("./EX2/data/result.csv").sort_values(by="pred",ascending=False).reset_index(drop=True)

  data["tp_cumsum"] = (data["label"] == 1).cumsum()
  data["fp_cumsum"] = (data["label"] == 0).cumsum()

  total_pos = (data["label"] == 1).sum()

  data["precision"] = data["tp_cumsum"] / (data["tp_cumsum"] + data["fp_cumsum"])
  data["recall"] = data["tp_cumsum"] / total_pos

  recall = np.r_[0.0, data["recall"].to_numpy()]
  precision = np.r_[1.0, data["precision"].to_numpy()]

# 计算 AUPR（recall 单调增时可用梯形法则）
  aupr = np.trapz(precision, recall)

  plt.figure()
  plt.step(recall, precision, where="post")
  plt.xlabel("Recall")
  plt.ylabel("Precision")
  plt.title(f"Precision–Recall Curve (AUPR = {aupr:.4f})")
  plt.xlim(0, 1)
  plt.ylim(0, 1)
  plt.grid(True)
  plt.savefig("./EX2/PR_curve.png")
  plt.show()
\end{lstlisting}
\clearpage
\chapter{第三次上机实验}
\section{实验要求}

1. 使用给定sklearn库中内置乳腺癌数据集，学习得到一个Fisher分类器
2. 对测试样本进行分类
3. 使用Python编程实现

\section{数据分析与处理}

本实验使用的是 \texttt{scikit-learn} 库提供的乳腺癌数据集。
该数据集包含 569 个样本、30 个连续特征以及一个二分类标签（0 表示恶性，1 表示良性），
数据字典中"data"和"target"分别给出了特征和对应的分类标签。

将数据集按 8:2 的比例随机划分为训练集和测试集，

\section{实验步骤与原理}

本实验旨在基于乳腺癌数据集构建 Fisher 线性判别分类器，
并对测试样本进行二分类评估。
Fisher 判别的核心思想是寻找一个投影方向，
使得不同类别在该方向上的类间距离最大、类内距离最小，从而实现最优线性可分。

\subsection{实验原理}

设原始数据为特征矩阵 $\mathbf{X}\in\mathbb{R}^{n\times d}$，标签向量为 $y$。
Fisher 判别通过构造两类散度矩阵来刻画数据结构：

\begin{itemize}
    \item \textbf{类内散度矩阵（Within-Class Scatter）}
    \[
        \mathbf{S}_w=\sum_{k}\sum_{x_i\in C_k}(x_i-\mu_k)(x_i-\mu_k)^{T},
    \]
    其中 $\mu_k$ 为第 $k$ 类的均值。该矩阵衡量同一类别样本的紧凑程度。
    
    \item \textbf{类间散度矩阵（Between-Class Scatter）}
    \[
        \mathbf{S}_b=\sum_{k}n_k(\mu_k-\mu)(\mu_k-\mu)^{T},
    \]
    其中 $\mu$ 为全局均值，$n_k$ 为类别 $k$ 的样本数。该矩阵表示类别均值之间的分离程度。
\end{itemize}

Fisher 判别寻求一个最优投影方向 $w$，使得类间散度与类内散度之比最大，即：
\[
    w=\arg\max_{w}\frac{w^{T}\mathbf{S}_b w}{w^{T}\mathbf{S}_w w}.
\]
这一优化问题,利用拉格朗日乘子法，可转化为广义特征值问题：
\[
    \mathbf{S}_b w = \lambda \mathbf{S}_w w,
\]
从中选取对应最大特征值的特征向量作为最优判别方向。

得到投影方向后，将训练样本投影到该方向，并计算各类别投影均值。类别之间的阈值取为相邻类别投影均值的中点，随后根据投影大小实现分类。

\subsection{实验步骤}

实验步骤如下：

\begin{enumerate}
    \item \textbf{数据加载与标注}：导入乳腺癌数据集，获取特征矩阵与标签向量。
    
    \item \textbf{数据划分}：采用随机划分方式，将数据按 8:2 的比例分为训练集与测试集。
    
    \item \textbf{计算散度矩阵}：对训练集分别计算类内散度矩阵 $\mathbf{S}_w$ 和类间散度矩阵 $\mathbf{S}_b$。
    
    \item \textbf{求解最优判别方向}：通过广义特征分解求得 Fisher 判别方向 $w$。
    
    \item \textbf{生成分类阈值}：将训练样本投影到 $w$ 上，根据各类别投影均值计算分类阈值。
    
    \item \textbf{模型预测}：将测试集样本投影到 $w$ 上，依据阈值进行类别判别。
    
    \item \textbf{模型评估}：计算预测精度，评价 Fisher 分类器在测试集上的分类性能。
\end{enumerate}

该流程完整实现了 Fisher 线性判别的训练与预测过程，验证了其在二分类任务中的有效性。

\section{实验结论与分析}
在完成 Fisher 线性判别分类器的训练与测试后，对测试集样本进行了分类评估。
本实验采用准确率（Accuracy）与混淆矩阵（Confusion Matrix）作为主要性能指标。

\subsection{分类准确率}
在固定numpy随机种子为42的情况下，得到如下结果。

分类准确率为：
\[
\text{Accuracy} = 97.37\%
\]
该结果表明 Fisher 判别在乳腺癌二分类任务中具有良好的判别能力，能够在一维投影空间中实现有效的类别分离。

\subsection{混淆矩阵分析}

为了进一步观察分类器在不同类别上的预测情况，绘制其混淆矩阵如下：

\[
\begin{pmatrix}
44 & 3 \\
0 & 67
\end{pmatrix}
\]

其中：

\begin{itemize}
    \item 第一行表示真实标签为恶性（0）的样本，共 47 个，其中正确分类 44 个，误判为良性 3 个；
    \item 第二行表示真实标签为良性（1）的样本，共 67 个，全部被正确分类。
\end{itemize}

从矩阵可以看出，分类器对良性样本的识别效果好（无误判），对恶性样本也能保持较高的识别率。整体来看，该 Fisher 分类器在测试集上表现稳定，具有较强的泛化能力。
但是存在将恶性样本误判为良性样本的情况，从错误代价的角度考虑，仍有较大的改进空间.

\section{实验代码}
\begin{lstlisting}[language=Python]

"""Fisher's Linear Discriminant Classifier Implementation"""

import scipy
import numpy as np
from sklearn.datasets import load_breast_cancer
from typing import List,Tuple

def get_Sw(X: np.ndarray, y: np.ndarray) -> np.ndarray:
    """Coumpute Within-Class Scatter Matrix"""
    labels = np.unique(y)
    n_features = X.shape[1]
    Sw = np.zeros((n_features, n_features))
    for label in labels:
        XOfLabel = X[y == label]
        meanOfClass = np.mean(XOfLabel, axis=0)
        diff = XOfLabel - meanOfClass
        Sw += diff.T @ diff
    return Sw


def get_Sb(X: np.ndarray, y: np.ndarray) -> np.ndarray:
    """Compute Between-Class Scatter Matrix"""
    overallMean = np.mean(X, axis=0)
    labels = np.unique(y)
    n_features = X.shape[1]
    Sb = np.zeros((n_features, n_features))
    for label in labels:
        XOfLabel = X[y == label]
        n_samplesOfLabel = XOfLabel.shape[0]
        meanOfClass = np.mean(XOfLabel, axis=0)
        meanDiff = (meanOfClass - overallMean).reshape(n_features, 1)
        Sb += n_samplesOfLabel * (meanDiff @ meanDiff.T)
    return Sb


def solve_fisher_direction(X: np.ndarray, y: np.ndarray) -> np.ndarray:
    """Solve for Fisher's Linear Discriminant Direction"""
    Sw = get_Sw(X, y)
    Sb = get_Sb(X, y)

    # Solve the generalized eigenvalue problem equation Sb*w = lambda*Sw*w
    eigvals, eigvecs = scipy.linalg.eigh(Sb, Sw)
    maxEigIndex = np.argmax(eigvals)
    w = eigvecs[:, maxEigIndex]
    return w


def split_data(X: np.ndarray, y: np.ndarray, train_ratio: float = 0.8):
    """Split data into training and testing sets"""
    n_samples = X.shape[0]
    indices = np.arange(n_samples)
    np.random.shuffle(indices)

    train_size = int(n_samples * train_ratio)
    train_indices = indices[:train_size]
    test_indices = indices[train_size:]

    X_train = X[train_indices]
    y_train = y[train_indices]
    X_test = X[test_indices]
    y_test = y[test_indices]

    return X_train, y_train, X_test, y_test


def train_fisher_classifier(X: np.ndarray, y: np.ndarray):
    """Train Fisher Classifier"""
    w = solve_fisher_direction(X, y)
    projections = X @ w  # compute projection
    labels = np.unique(y)
    meanProjections = []
    for label in labels:
        meanProjections.append((label,np.mean(projections[y == label])))
    sortedMeans = sorted(meanProjections,key=lambda x: x[1])
    thresholds=[]
    for i in range(len(sortedMeans)-1):
        meanPrev=sortedMeans[i][1]
        meanPost=sortedMeans[i+1][1]
        thresholds.append((meanPrev+meanPost)/2)

    return w,thresholds,sortedMeans


def predict_fisher_classifier(X: np.ndarray, w: np.ndarray, thresholds: list,sortedMeans:List[Tuple[int,float]]) -> np.ndarray:
    """Predict using Fisher Classifier"""
    projections = X @ w
    y_pred = np.zeros(projections.shape[0])
    labels = [item[0] for item in sortedMeans]
    for i, projection in enumerate(projections):
        for j, threshold in enumerate(thresholds):
            if projection < threshold:
                y_pred[i] = labels[j]
                break
        else:
            y_pred[i] = labels[-1]
    return y_pred

def evaluate_classifier(y_true: np.ndarray, y_pred: np.ndarray):
    """Evaluate Classifier Accuracy"""
    accuracy = np.mean(y_true == y_pred)
    return accuracy




if __name__ == "__main__":
    np.random.seed(42)
    
    data = load_breast_cancer()
    X = data["data"]
    y = data["target"]

    X_train, y_train, X_test, y_test = split_data(X, y)

    w,thresholds,sortedMeans = train_fisher_classifier(X_train, y_train)

    y_pred = predict_fisher_classifier(X_test, w, thresholds,sortedMeans)

    accuracy = evaluate_classifier(y_test, y_pred)
    print(f"Fisher Classifier Accuracy: {accuracy * 100:.2f}%")
\end{lstlisting}
\clearpage
\chapter{第四次上机实验}
\section{实验要求}
\section{数据分析与处理}
\section{实验步骤与原理}
\section{实验结论与分析}
\section{实验代码}
\clearpage
\chapter{第五次上机实验}
\section{实验要求}
\section{数据分析与处理}
\section{实验步骤与原理}
\section{实验结论与分析}
\section{实验代码}
\printbibliography

\end{document}
